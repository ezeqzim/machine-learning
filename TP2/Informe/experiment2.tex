\subsection{¿Aprende un Q-Learner entrenado contra otro Q-Learner?}

El enfoque de este experimento fue observar cómo se comportan dos Q-Learner al entrenar compitiendo entre sí, para determinar si los resultados obtenidos indicaban una mejoría en sus estrategias de juego.
Luego, cada uno de éstos compitió contra un jugador Random durante la misma cantidad de iteraciones y se graficaron los resultados.

\ig{Imagenes/Results/exp2/gridsearch/gridsearch_training_acum.png}{Porcentaje de victorias de cada Q-Learner a lo largo de las iteraciones}

Ambos Q-Learners comienzan demostrando una baja inteligencia, ya que ambos realizan jugadas aleatorias al principio. Sin embargo, conforme avanzan las iteraciones, ambos comienzan a realizar mejores movimientos, y se puede observar que mejoran a un ritmo similar, dado que el porcentaje de victorias de cada uno tiende al 50\% al final, indicando que ambos tienen una estrategia para vencer al otro.\\

Por los resultados obtenidos, se conjeturó que, una vez entrenado el Q-Learner, obtendrá más victorias contra el jugador Random que los obtenidos en el experimento anterior, cuando entrenó únicamente contra un jugador Random.
Dicha conjetura se condijo con los resultados obtenidos.

\ig{Imagenes/Results/exp2/gridsearch/gridsearch_p1_test_acum.png}{Porcentaje de victorias de cada Q-Learner a lo largo de las iteraciones}

\textcolor{red}{Nuestra conjetura es que se obtuvieron mejores resultados porque el enfrentamiento entre dos Q-Learners representa un desafío mayor que enfrentar a un jugador Random, dado que al jugador Random se le puede vencer con facilidad, en la mayoría de los casos, simplemente ubicando fichas en una misma columna.}
