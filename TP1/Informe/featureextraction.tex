\section{Extracción de atributos}

En un principio la idea original que se intentó seguir fue la de tomar las palabras más comunes tanto de los correos de \emph{ham} como los de \emph{spam}. Para esto se utilizó el \texttt{CountVectorizer} de \texttt{Sklearn}, utilizando el parámetro \texttt{max\_features}, que ordena las palabras del texto por frecuencia, es decir, cantidad de apariciones, y sólo se queda con las más frecuentes.

Para efectuar el \texttt{split} de dichas palabras, se utilizo una expresión regular que toma aquellas con letras y números y las separa con los signos de puntuación. Se decidió ignorar las palabras que consistían únicamente de números. Al realizar una prueba se notó que las primeras en la lista de palabras más frecuentes eran palabras de \texttt{HTML} o palabras de los \texttt{HEADERs} de los correos. También se notó que hubo apareciones de palabras que consistían de caracteres en principio aleatorios, principalmente en \emph{ham}. Tras investigar de qué correos provenían estas palabras, se descubrió que se debía a los archivos adjuntos.

Luego se intentó utilizar un parser de correos\textsuperscript{\cite{parser}} para quedarnos únicamente con el cuerpo del correo electr\'onico. Durante esta etapa surgieron problemas con los correos multiparte. Al pedirle el \texttt{payload}, éstos devolvían una lista de partes, de las cuales no se pudo extraer el cuerpo del correo. Tras una discusión entre los integrantes del grupo, se decidió no utilizar esta herramienta, no solo por las dificultades ocasionadas, sino porque nos result\'o interesante mantener los archivos adjuntos. En cuanto a los \texttt{HEADERs}, no se quitaron pero se decidió tomar todos los correos y tomar las 500 palabras más comunes en total. Esta decisión se basó en la idea de que de ésta forma se obtendrían las palabras más comunes más allá de los \texttt{HEADERs}. Si bien estos atributos aparec\'ian frecuentemente (ya que constituyen la estructura de cualquier correo electr\'onico v\'alido) podrían entorpecer a clasificadores como \emph{K Nearest Neighbours}, otros clasificadores como los árboles de decisión, podrían dejarlos de lado si se utiliza, por ejemplo, el criterio de la entropía, dado que no ayudarían a separar los datos. Más aún, serían los primeros en ser dejados de lado por métodos de reducción de dimensionalidad.

Finalmente, los atributos elegidos fueron las frecuencias de las 500 palabras más comunes en el total de los correos.